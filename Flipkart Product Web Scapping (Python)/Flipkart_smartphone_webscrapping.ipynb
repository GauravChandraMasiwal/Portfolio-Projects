{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1989e24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "import requests\n",
    "import html5lib\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6b2292ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_title(soup):\n",
    "    try :\n",
    "        title = soup.find(\"span\",attrs = {'class':'B_NuCI'}).text.strip()\n",
    "    except AttributeError:\n",
    "        title = ''\n",
    "    return title\n",
    "\n",
    "def get_price_sale(soup):\n",
    "    try :\n",
    "        price_sale= soup.find(\"div\",attrs = {'class':'_30jeq3 _16Jk6d'}).text.strip()\n",
    "        \n",
    "    except AttributeError:\n",
    "        price_sale = ''\n",
    "        \n",
    "    return price_sale\n",
    "\n",
    "def get_price_original(soup):\n",
    "    try :\n",
    "        price_original = soup.find(\"div\",attrs = {'class':'_3I9_wc _2p6lqe'}).text.strip()\n",
    "        \n",
    "    except AttributeError:\n",
    "        price_original = ''\n",
    "        \n",
    "    return price_original\n",
    "\n",
    "def get_rating(soup):\n",
    "    try :\n",
    "        rating = soup.find(\"div\",attrs = {'class':'_3LWZlK'}).text.strip()\n",
    "    except AttributeError:\n",
    "        rating = ''\n",
    "    return rating\n",
    "\n",
    "def get_rating_reviews(soup):\n",
    "    try :\n",
    "        r_r = soup.find(\"span\",attrs = {'class':'_2_R_DZ'}).text.strip()\n",
    "    except AttributeError:\n",
    "        r_r = ''\n",
    "    return r_r\n",
    "\n",
    "\n",
    "def smartphone_scrapper(dictionary,url):\n",
    "    flip_url = \"https://flipkart.com\"\n",
    "    \n",
    "    Headers = ({'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36', 'Accept-Language': 'en-US, en;q=0.5'})\n",
    "    \n",
    "    webpage = requests.get(url,headers = Headers)\n",
    "    \n",
    "    soup = BeautifulSoup(webpage.text,\"html.parser\")\n",
    "    \n",
    "    next_url = soup.find_all('a',attrs = {'class':'_1LKTO3'})[-1]\n",
    "    next_url_text = next_url.get_text()\n",
    "    \n",
    "    if next_url != None and next_url_text == 'Next':\n",
    "        \n",
    "        next_url = next_url.get('href')\n",
    "        \n",
    "        product_links = soup.find_all(\"a\",attrs = {'class':'_1fQZEK'})\n",
    "    \n",
    "        links = []\n",
    "        \n",
    "        for link in product_links :\n",
    "            links.append(flip_url + link.get('href'))\n",
    "        \n",
    "        for link in links:\n",
    "            new_webpage = requests.get(link,headers = Headers)\n",
    "            soup_new = BeautifulSoup(new_webpage.text,'html.parser')\n",
    "        \n",
    "            dictionary['Product_Name'].append(get_title(soup_new))\n",
    "            dictionary['Original_Price'].append(get_price_original(soup_new))\n",
    "            dictionary['Sale_Price'].append(get_price_sale(soup_new))\n",
    "            dictionary['Ratings_out_of_5'].append(get_rating(soup_new))\n",
    "            dictionary['Ratings and Reviews'].append(get_rating_reviews(soup_new))\n",
    "            dictionary['Date'].append(datetime.now())\n",
    "        new_dictionary = dictionary.copy()\n",
    "        \n",
    "        url = flip_url + next_url\n",
    "        print(len(new_dictionary['Product_Name']), \" products extracted successfully\")\n",
    "        smartphone_scrapper(new_dictionary,url)\n",
    "        \n",
    "    else : \n",
    "        product_links = soup.find_all(\"a\",attrs = {'class':'_1fQZEK'})\n",
    "    \n",
    "        links = []\n",
    "        \n",
    "        for link in product_links :\n",
    "            links.append(flip_url + link.get('href'))\n",
    "        new_dictionary = dictionary.copy()\n",
    "        for link in links:\n",
    "            new_webpage = requests.get(link,headers = Headers)\n",
    "            soup_new = BeautifulSoup(new_webpage.text,'html.parser')\n",
    "        \n",
    "            new_dictionary['Product_Name'].append(get_title(soup_new))\n",
    "            new_dictionary['Original_Price'].append(get_price_original(soup_new))\n",
    "            new_dictionary['Sale_Price'].append(get_price_sale(soup_new))\n",
    "            new_dictionary['Ratings_out_of_5'].append(get_rating(soup_new))\n",
    "            new_dictionary['Ratings and Reviews'].append(get_rating_reviews(soup_new))\n",
    "            new_dictionary['Date'].append(datetime.now())\n",
    "        \n",
    "        print(len(new_dictionary['Product_Name']), \" products extracted successfully\")\n",
    "        \n",
    "        flipkart_df = pd.DataFrame.from_dict(new_dictionary)\n",
    "        flipkart_df.replace('', np.nan, inplace=True)\n",
    "        flipkart_df = flipkart_df.dropna(subset=['Product_Name'])\n",
    "        flipkart_df.to_csv(\"flipkart.csv\", header=True, index=False)\n",
    "        print('csv file for data is created!')\n",
    "        #flipkart_df = pd.DataFrame.from_dict(dictionary)\n",
    "        \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "eb2d3be9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24  products extracted successfully\n",
      "48  products extracted successfully\n",
      "72  products extracted successfully\n",
      "96  products extracted successfully\n",
      "120  products extracted successfully\n",
      "144  products extracted successfully\n",
      "168  products extracted successfully\n",
      "192  products extracted successfully\n",
      "216  products extracted successfully\n",
      "240  products extracted successfully\n",
      "264  products extracted successfully\n",
      "288  products extracted successfully\n",
      "312  products extracted successfully\n",
      "336  products extracted successfully\n",
      "360  products extracted successfully\n",
      "384  products extracted successfully\n",
      "408  products extracted successfully\n",
      "432  products extracted successfully\n",
      "csv file for data is created!\n"
     ]
    }
   ],
   "source": [
    "url_iphone = \"https://www.flipkart.com/search?q=iphone&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=on&as=off\"\n",
    "dictionary_iphone = {'Product_Name':[],'Original_Price':[],'Sale_Price':[],'Ratings_out_of_5':[],'Ratings and Reviews':[],'Date':[]}\n",
    "smartphone_scrapper(dictionary_iphone,url_iphone)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60568937",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b69c7ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4094e148",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca756b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e326ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
